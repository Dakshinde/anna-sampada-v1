{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda22172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Roti Spoilage Detector ML Training Pipeline ---\n",
      "Target model file: roti_spoiler_pipeline.joblib\n",
      "Dataset size: 3500 rows\n",
      "\n",
      "==================================================\n",
      "\n",
      "Data Generated successfully. Shape: (3493, 8)\n",
      "Spoilage Distribution:\n",
      "roti_state\n",
      "1    0.542227\n",
      "0    0.457773\n",
      "Name: proportion, dtype: float64\n",
      "   time_since_cooking_hr  storage_location    storage_container  \\\n",
      "0                   27.3  Room Temperature         Airtight Box   \n",
      "1                   68.5      Open Counter         Airtight Box   \n",
      "2                   52.8          Lunchbox           Open Plate   \n",
      "3                   43.3  Room Temperature           Ziploc Bag   \n",
      "4                   11.7      Open Counter  Aluminium Foil Wrap   \n",
      "\n",
      "      fat_content ambient_season   observed_texture observed_appearance  \\\n",
      "0      Low (0-5%)   Warm & Humid     Soft & Pliable     Lightly Spotted   \n",
      "1      Low (0-5%)   Warm & Humid     Soft & Pliable        Golden Brown   \n",
      "2  Medium (5-10%)        Neutral       Slimy/Sticky     Lightly Spotted   \n",
      "3      Low (0-5%)     Cool & Dry     Soft & Pliable        Golden Brown   \n",
      "4  Medium (5-10%)        Neutral  Slightly Hardened        Golden Brown   \n",
      "\n",
      "   roti_state  \n",
      "0           1  \n",
      "1           1  \n",
      "2           1  \n",
      "3           1  \n",
      "4           0  \n",
      "\n",
      "==================================================\n",
      "\n",
      "Numerical Features: ['time_since_cooking_hr']\n",
      "Categorical Features: ['storage_location', 'storage_container', 'fat_content', 'ambient_season', 'observed_texture', 'observed_appearance']\n",
      "ColumnTransformer set up for scaling numerical features and OHE categorical features.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Data split into Train (2794) and Test (699) sets.\n",
      "\n",
      "Training Logistic Regression...\n",
      "  -> Test Accuracy: 0.9070\n",
      "\n",
      "Training Random Forest...\n",
      "  -> Test Accuracy: 0.9442\n",
      "\n",
      "Training Gradient Boosting (XGB)...\n",
      "  -> Test Accuracy: 0.9442\n",
      "\n",
      "==================================================\n",
      "BEST MODEL: Random Forest with Accuracy: 0.9442\n",
      "Classification Report for Best Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fresh       0.90      0.99      0.94       320\n",
      "     Spoiled       0.99      0.90      0.95       379\n",
      "\n",
      "    accuracy                           0.94       699\n",
      "   macro avg       0.94      0.95      0.94       699\n",
      "weighted avg       0.95      0.94      0.94       699\n",
      "\n",
      "==================================================\n",
      "\n",
      "SUCCESS: The complete ML pipeline has been saved to 'roti_spoiler_pipeline.joblib'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_FILE = 'roti_spoiler_pipeline.joblib'\n",
    "N_SAMPLES = 3500\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"--- Roti Spoilage Detector ML Training Pipeline ---\")\n",
    "print(f\"Target model file: {MODEL_FILE}\")\n",
    "print(f\"Dataset size: {N_SAMPLES} rows\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. DATA GENERATION (Embedding Custom Spoilage Logic)\n",
    "# ==============================================================================\n",
    "\n",
    "def generate_synthetic_data(n_samples):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset for Roti spoilage detection, embedding the logical constraints.\n",
    "    roti_state: 1 = Spoiled, 0 = Fresh/Safe\n",
    "    \"\"\"\n",
    "    # Define categories based on typical scenarios\n",
    "    storage_locations = ['Room Temperature', 'Refrigerator', 'Freezer', 'Open Counter', 'Lunchbox']\n",
    "    storage_containers = ['Airtight Box', 'Aluminium Foil Wrap', 'Cloth/Basket', 'Ziploc Bag', 'Open Plate']\n",
    "    fat_contents = ['Low (0-5%)', 'Medium (5-10%)', 'High (>10%)']\n",
    "    ambient_seasons = ['Warm & Humid', 'Cool & Dry', 'Neutral', 'Monsoon (Very Humid)']\n",
    "    observed_textures = ['Soft & Pliable', 'Slightly Hardened', 'Dry & Brittle', 'Slimy/Sticky', 'Fuzzy/Mold']\n",
    "    observed_appearances = ['Golden Brown', 'Lightly Spotted', 'Dark Patches', 'Oil Separation/Condensation', 'Visible Fuzz/Growth']\n",
    "\n",
    "    # Generate features\n",
    "    df = pd.DataFrame({\n",
    "        'time_since_cooking_hr': np.random.uniform(0.5, 72, n_samples).round(1),\n",
    "        'storage_location': np.random.choice(storage_locations, n_samples, p=[0.4, 0.3, 0.1, 0.1, 0.1]),\n",
    "        'storage_container': np.random.choice(storage_containers, n_samples, p=[0.3, 0.2, 0.2, 0.1, 0.2]),\n",
    "        'fat_content': np.random.choice(fat_contents, n_samples, p=[0.4, 0.4, 0.2]),\n",
    "        'ambient_season': np.random.choice(ambient_seasons, n_samples, p=[0.3, 0.3, 0.3, 0.1]),\n",
    "        'observed_texture': np.random.choice(observed_textures, n_samples, p=[0.6, 0.2, 0.1, 0.05, 0.05]),\n",
    "        'observed_appearance': np.random.choice(observed_appearances, n_samples, p=[0.6, 0.2, 0.1, 0.05, 0.05]),\n",
    "    })\n",
    "\n",
    "    df['roti_state'] = 0 # Initialize as fresh\n",
    "\n",
    "    # --- Apply Core Spoilage Logic (Training the model to understand context) ---\n",
    "\n",
    "    # 1. HARD SPOILAGE RULE (Time/Temp): >24 hours at Room Temp\n",
    "    rule_1 = (df['time_since_cooking_hr'] > 24) & (df['storage_location'] == 'Room Temperature')\n",
    "    df.loc[rule_1, 'roti_state'] = 1\n",
    "\n",
    "    # 2. SENSORY INDICATORS: Strong visual/texture signs = Spoiled\n",
    "    rule_2 = (df['observed_texture'].isin(['Slimy/Sticky', 'Fuzzy/Mold'])) | \\\n",
    "             (df['observed_appearance'].isin(['Visible Fuzz/Growth', 'Dark Patches']))\n",
    "    df.loc[rule_2, 'roti_state'] = 1\n",
    "\n",
    "    # 3. MOISTURE RISK: Condensation + Medium time = Higher Spoilage Chance\n",
    "    rule_3 = (df['observed_appearance'] == 'Oil Separation/Condensation') & \\\n",
    "             (df['time_since_cooking_hr'] > 6) & (df['time_since_cooking_hr'] <= 48) & \\\n",
    "             (df['roti_state'] == 0)\n",
    "    df.loc[rule_3, 'roti_state'] = np.random.choice([0, 1], size=rule_3.sum(), p=[0.2, 0.8])\n",
    "\n",
    "    # 4. LOW RISK: Refrigerated/Frozen (Extremely low spoilage probability)\n",
    "    rule_4 = df['storage_location'].isin(['Refrigerator', 'Freezer']) & (df['roti_state'] == 0)\n",
    "    df.loc[rule_4, 'roti_state'] = np.random.choice([0, 1], size=rule_4.sum(), p=[0.99, 0.01])\n",
    "\n",
    "    # 5. AMBIENT RISK: Warm & Humid / Monsoon + Moderate Time\n",
    "    rule_5 = df['ambient_season'].isin(['Warm & Humid', 'Monsoon (Very Humid)']) & \\\n",
    "             (df['time_since_cooking_hr'] > 8) & (df['roti_state'] == 0)\n",
    "    df.loc[rule_5, 'roti_state'] = np.random.choice([0, 1], size=rule_5.sum(), p=[0.7, 0.3])\n",
    "\n",
    "    # 6. Global Time Max: Anything over 60 hours is spoiled unless frozen/refrigerated\n",
    "    rule_6 = (df['time_since_cooking_hr'] > 60) & \\\n",
    "             ~df['storage_location'].isin(['Refrigerator', 'Freezer'])\n",
    "    df.loc[rule_6, 'roti_state'] = 1\n",
    "\n",
    "    return df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df = generate_synthetic_data(N_SAMPLES)\n",
    "print(f\"Data Generated successfully. Shape: {df.shape}\")\n",
    "print(f\"Spoilage Distribution:\\n{df['roti_state'].value_counts(normalize=True)}\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. FEATURE ENGINEERING AND PREPROCESSING\n",
    "# ==============================================================================\n",
    "\n",
    "X = df.drop('roti_state', axis=1)\n",
    "y = df['roti_state']\n",
    "\n",
    "# Define feature types\n",
    "numerical_features = ['time_since_cooking_hr']\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical Features: {numerical_features}\")\n",
    "print(f\"Categorical Features: {categorical_features}\")\n",
    "\n",
    "# Create the preprocessing pipelines\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    # handle_unknown='ignore' ensures robustness when unseen categories appear (though unlikely here)\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "print(\"ColumnTransformer set up for scaling numerical features and OHE categorical features.\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. MODEL TRAINING AND SELECTION\n",
    "# ==============================================================================\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\n",
    "print(f\"Data split into Train ({X_train.shape[0]}) and Test ({X_test.shape[0]}) sets.\")\n",
    "\n",
    "# Define candidate models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='liblinear', random_state=SEED),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=SEED),\n",
    "    'Gradient Boosting (XGB)': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=SEED)\n",
    "}\n",
    "\n",
    "best_model_name = None\n",
    "best_accuracy = 0\n",
    "best_pipeline = None\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    # Create full pipeline (preprocessor + model)\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "\n",
    "    # Train\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"  -> Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_name = name\n",
    "        best_pipeline = pipeline\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"BEST MODEL: {best_model_name} with Accuracy: {best_accuracy:.4f}\")\n",
    "print(\"Classification Report for Best Model:\")\n",
    "y_pred_best = best_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Fresh', 'Spoiled']))\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. MODEL PERSISTENCE (Saving the best pipeline)\n",
    "# ==============================================================================\n",
    "\n",
    "if best_pipeline:\n",
    "    # Save the entire pipeline, including preprocessing steps\n",
    "    joblib.dump(best_pipeline, MODEL_FILE)\n",
    "    print(f\"SUCCESS: The complete ML pipeline has been saved to '{MODEL_FILE}'.\")\n",
    "else:\n",
    "    print(\"ERROR: No model pipeline was selected or saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
